"""
LangChain æ•´åˆæ¨¡çµ„
å®Œæ•´è¤‡è£½ solution_combine.py çš„ LangChain å¯¦ç¾åˆ° Streamlit æ‡‰ç”¨
"""
import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Any
import streamlit as st
from .hotai_tools import get_all_tools, generate_mapping_text, BusinessCalculator, dataframes

# LangChain imports
try:
    from langchain_openai import ChatOpenAI
    from langchain.tools import tool
    from langchain.agents import AgentExecutor, create_openai_functions_agent
    from langchain.prompts import ChatPromptTemplate
    from langchain.tools.render import format_tool_to_openai_function
    from langchain.callbacks import get_openai_callback
    from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False


class StreamlitLangChainAgent:
    """Streamlit æ•´åˆçš„ LangChain Agent - åŸºæ–¼ solution_combine.py"""
    
    def __init__(self):
        self.llm = None
        self.agent_executor = None
        self.tools = []
        self.mapping_text = ""
        self.setup_agent()
    
    def setup_agent(self):
        """è¨­ç½® LangChain Agent"""
        if not LANGCHAIN_AVAILABLE:
            st.error("âŒ LangChain å¥—ä»¶æœªå®‰è£ï¼Œè«‹æª¢æŸ¥ requirements.txt")
            return
        
        # æª¢æŸ¥ API é‡‘é‘°
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            st.warning("âš ï¸ OpenAI API Key æœªè¨­å®šï¼Œç„¡æ³•ä½¿ç”¨ AI å•ç­”åŠŸèƒ½")
            return
        
        try:
            # åˆå§‹åŒ–èªè¨€æ¨¡å‹ï¼ˆèˆ‡åŸç¨‹å¼ä¿æŒä¸€è‡´ï¼‰
            self.llm = ChatOpenAI(temperature=0, model="gpt-4.1")
            
            # è¼‰å…¥æ˜ å°„è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            self.load_mapping_data()
            
            # è¨­ç½®å·¥å…·
            self.setup_tools()
            
            # å‰µå»º Agent
            if self.tools:
                self.create_agent()
                
        except Exception as e:
            st.error(f"âŒ LangChain Agent åˆå§‹åŒ–å¤±æ•—: {str(e)}")
    
    def load_mapping_data(self):
        """è¼‰å…¥æ˜ å°„è¡¨è³‡æ–™"""
        try:
            # æª¢æŸ¥æ˜¯å¦æœ‰æ˜ å°„è¡¨æª”æ¡ˆ
            mapping_files = ["Mapping Dataframe.xlsx", "mapping.xlsx", "ç¶“éŠ·å•†å°æ‡‰è¡¨.xlsx"]
            for filename in mapping_files:
                if hasattr(st.session_state, 'uploaded_data') and filename in st.session_state.uploaded_data:
                    self.mapping_text = generate_mapping_text(filename)
                    break
            
            if not self.mapping_text:
                self.mapping_text = "æ˜ å°„è¡¨è³‡æ–™æœªè¼‰å…¥ï¼Œç¶“éŠ·å•†åç¨±æŸ¥è©¢å¯èƒ½å—é™ã€‚"
        except Exception as e:
            self.mapping_text = f"æ˜ å°„è¡¨è¼‰å…¥å¤±æ•—: {str(e)}"
    
    def setup_tools(self):
        """è¨­ç½®åˆ†æå·¥å…· - ä½¿ç”¨å®Œæ•´çš„ HOTAI å·¥å…·é›†"""
        # å–å¾—æ‰€æœ‰ HOTAI å·¥å…·
        self.tools = get_all_tools()
        
        # æ–°å¢é¡å¤–çš„æ¥­å‹™è¨ˆç®—å·¥å…·
        @tool
        def calculate_business_metrics(metric_type: str, actual: float = 0, target: float = 1, 
                                     current: float = 0, previous: float = 1) -> str:
            """è¨ˆç®— HOTAI MOTOR æ¥­å‹™æŒ‡æ¨™"""
            calc = BusinessCalculator()
            try:
                if metric_type in ["é”æˆç‡", "achievement_rate"]:
                    rate = calc.calculate_achievement_rate(actual, target)
                    return f"é”æˆç‡: {rate:.1f}% (å¯¦ç¸¾ {actual} / ç›®æ¨™ {target})"
                elif metric_type in ["å»å¹´æ¯”", "yoy_growth"]:
                    growth = calc.calculate_yoy_growth(current, previous)
                    return f"å»å¹´æ¯”: {growth:.1f}% (ä»Šå¹´ {current} / å»å¹´ {previous})"
                elif metric_type in ["å‰æœˆæ¯”", "mom_growth"]:
                    growth = calc.calculate_mom_growth(current, previous)
                    return f"å‰æœˆæ¯”: {growth:.1f}% (æœ¬æœˆ {current} / ä¸Šæœˆ {previous})"
                elif metric_type in ["æ¨é€²ç‡", "progress_rate"]:
                    rate = calc.calculate_progress_rate(actual, target)
                    return f"æ¨é€²ç‡: {rate:.1f}% (ç›®å‰ {actual} / ç›®æ¨™ {target})"
                else:
                    return f"ä¸æ”¯æ´çš„æŒ‡æ¨™é¡å‹: {metric_type}ã€‚æ”¯æ´çš„é¡å‹: é”æˆç‡, å»å¹´æ¯”, å‰æœˆæ¯”, æ¨é€²ç‡"
            except Exception as e:
                return f"æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {str(e)}"
        
        @tool
        def get_system_status() -> str:
            """å–å¾—ç³»çµ±ç‹€æ…‹è³‡è¨Š"""
            status_info = []
            status_info.append(f"ğŸ“Š å·²è¼‰å…¥è³‡æ–™é›†: {len(dataframes)}")
            
            if hasattr(st.session_state, 'uploaded_data'):
                status_info.append(f"ğŸ“ å·²ä¸Šå‚³æª”æ¡ˆ: {len(st.session_state.uploaded_data)}")
                for filename, file_info in st.session_state.uploaded_data.items():
                    sheet_count = len(file_info['data'])
                    total_rows = sum(len(df) for df in file_info['data'].values())
                    status_info.append(f"  â€¢ {filename}: {sheet_count} å·¥ä½œè¡¨, {total_rows:,} è¡Œ")
            
            status_info.append(f"ğŸ”§ æ˜ å°„è¡¨ç‹€æ…‹: {'å·²è¼‰å…¥' if self.mapping_text and 'å¤±æ•—' not in self.mapping_text else 'æœªè¼‰å…¥'}")
            
            return "\n".join(status_info)
        
        # åŠ å…¥é¡å¤–å·¥å…·
        self.tools.extend([calculate_business_metrics, get_system_status])
    
    def create_agent(self):
        """å‰µå»º LangChain Agent - ä½¿ç”¨ solution_combine.py çš„å®Œæ•´åŸå§‹ system_message"""
        # å®Œæ•´è¤‡è£½ solution_combine.py ä¸­çš„ system_message
        system_message = f"""ä½ æ˜¯ä¸€å€‹è³‡æ–™åˆ†æåŠ©ç†ï¼Œèƒ½åŒæ™‚è™•ç†å…©å¤§é¡ä»»å‹™â”€â”€ã€Œä¸€èˆ¬æ€§è³‡æ–™æ¢ç´¢èˆ‡åˆ†æã€ä»¥åŠã€Œç›®æ¨™ vs. å¯¦éš› éŠ·å”®é”æ¨™æ¯”å°ã€ã€‚è«‹ä¾ç…§ä½¿ç”¨è€…å•é¡Œï¼Œè‡ªå‹•åˆ¤æ–·ä¸¦åŸ·è¡Œæœ€åˆé©çš„æµç¨‹ã€‚

  # é‹ç®—èˆ‡åè©å®šç¾©
  **å¸¸è¦‹é‹ç®—å®šç¾©ï¼š**
  1. **å»å¹´æ¯”** = ä»Šå¹´å¯¦ç¸¾å°æ•¸ / å»å¹´å¯¦ç¸¾å°æ•¸ Ã— 100%  
     ä¾‹ï¼š2024å¹´3æœˆ100å°ï¼Œ2025å¹´3æœˆ150å° â†’ 150/100Ã—100%=150%
  2. **å‰æœˆæ¯”** = æœ¬æœˆå¯¦ç¸¾å°æ•¸ / ä¸Šæœˆå¯¦ç¸¾å°æ•¸ Ã— 100%  
     ä¾‹ï¼š2025å¹´2æœˆ150å°ï¼Œ2025å¹´3æœˆ100å° â†’ 100/150Ã—100%=66.7%
  3. **å»å¹´åŒæœŸæ¯”** = ä»Šå¹´åŒæœŸå°æ•¸ / å»å¹´åŒæœŸå°æ•¸ Ã— 100%  
     ä¾‹ï¼š2024/3/1â€“25åˆè¨ˆ100å°ï¼Œ2025/3/1â€“25åˆè¨ˆ150å° â†’ 150/100Ã—100%=150%
  4. **å‰æœˆåŒæœŸæ¯”** = æœ¬æœˆåŒæœŸå°æ•¸ / ä¸ŠæœˆåŒæœŸå°æ•¸ Ã— 100%  
     ä¾‹ï¼š2025/2/1â€“25åˆè¨ˆ150å°ï¼Œ2025/3/1â€“25åˆè¨ˆ100å° â†’ 100/150Ã—100%=66.7%
  5. **æ¨é€²ç‡** = å¯¦ç¸¾å°æ•¸ / ç›®æ¨™å°æ•¸ Ã— 100%ï¼ˆç”¨æ–¼ç•¶æœˆä¸­é€²åº¦ï¼‰  
     ä¾‹ï¼š5æœˆç›®æ¨™100å°ï¼Œè‡³ä»Šå·²è³£89å° â†’ 89/100Ã—100%=89%
  6. **é”æˆç‡** = å¯¦ç¸¾å°æ•¸ / ç›®æ¨™å°æ•¸ Ã— 100%ï¼ˆç”¨æ–¼å·²çµæŸæœˆä»½ï¼‰  
     ä¾‹ï¼š3æœˆç›®æ¨™100å°ï¼Œå¯¦ç¸¾92å° â†’ 92/100Ã—100%=92%
  7. **ç´¯è¨ˆå°æ•¸**ï¼šè‹¥ç„¡ç‰¹åˆ¥èªªæ˜æ™‚é–“ï¼Œé è¨­ç‚ºç•¶å¹´1/1è‡³æŒ‡å®šæ™‚é–“ä¹‹ç´¯è¨ˆã€‚

  **å¸¸è¦‹åè©å®šç¾©ï¼š**
  - **C CROSS** ç°¡ç¨± **CC**  
  - **Y CROSS** ç°¡ç¨± **YC**  
  - **HV** èˆ‡ **HEV** åŒç¾©ï¼Œå‡æŒ‡æ²¹é›»è»Š  
  - **æ“šé»** = **ç‡Ÿæ¥­æ‰€**  
  - **å¤§ç›¤** = **å…¨é«”é€²åº¦**
  - **ä»£è™Ÿ** = **ä»£ç¢¼**

  ## Excel æ¬„ä½èªªæ˜
  - **ç¶“éŠ·å•†ç›®æ¨™ Excel**  
    - æª”åæ¨¡å¼ï¼š`ç›®æ¨™_YYYYä¸ŠåŠå¹´.xlsx`ï¼Œsheet åç¨±åŒ  
    - ç›®æ¨™ç¨®é¡æ¬„ä½ï¼š`ç›®æ¨™ç¨®é¡`ï¼Œå…¶ä¸­ `1`ï¼å—è¨‚ã€`2`ï¼è²©è³£  
    - ç›®æ¨™å€¼æ¬„ä½ï¼š`Xæœˆç›®æ¨™`ã€`Yæœˆç›®æ¨™`â€¦ æˆ–é€šç”¨æ¬„ä½ `ç›®æ¨™æ•¸`
  - **MBIS å¯¦ç¸¾ Excel**  
    - æª”åæ¨¡å¼ï¼š`å¯¦ç¸¾_YYYYä¸ŠåŠå¹´.xlsx`ï¼Œsheet åç¨±åŒ  
    - å¯¦ç¸¾ç¨®é¡æ¬„ä½ï¼š`å¯¦ç¸¾ç¨®é¡`ï¼Œå…¶ä¸­ `27`ï¼å—è¨‚ã€`3D`ï¼è²©è³£  
    - å¯¦ç¸¾å€¼æ¬„ä½ï¼š`å—è¨‚æ•¸`ï¼ˆå—è¨‚ï¼‰æˆ– `éŠ·å”®æ•¸`ï¼ˆè²©è³£ï¼‰  
    - **ä½¿ç”¨æ™‚çµ±ä¸€ç¨±ä½œ** `å°æ•¸`ï¼Œä»£è¡¨å°æ‡‰çš„å¯¦ç¸¾å€¼

## æ¬„ä½å‹æ…‹è™•ç†
```python
# 1. æ—¥æœŸæ¬„ä½ï¼ˆDATE å‹æ…‹ï¼‰ï¼šå¼·åˆ¶è½‰ç‚º datetime
df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
# ç¯©é¸æ™‚å¯ç”¨ Timestamp æˆ– dt.date æ¯”å°
filtered = df[df['æ—¥æœŸ'] == pd.Timestamp('2025-05-22')]
# æˆ–è€…ï¼š
filtered = df[df['æ—¥æœŸ'].dt.date == pd.to_datetime('2025-05-22').date()]

# å­—ä¸²å‹æ…‹æ¯”å°å¼·åˆ¶è¦å‰‡
- å°æ–¼ä»»ä½• CHAR(2) é¡å‹çš„æ¬„ä½ï¼ˆå¦‚ `å¯¦ç¸¾ç¨®é¡`ï¼‰ï¼Œ**æ¨¡å‹ç”¢ç”Ÿçš„ç¨‹å¼ç¢¼**å¿…é ˆï¼š
  1. å…ˆåŸ·è¡Œ `df['å¯¦ç¸¾ç¨®é¡'] = df['å¯¦ç¸¾ç¨®é¡'].astype(str).str.strip()` æ¸…ç†ï¼›
  2. **æ¯”å°æ¢ä»¶å¿…é ˆ**ä½¿ç”¨å­—ä¸²å½¢å¼ï¼Œä¾‹å¦‚ï¼š
     ```python
     filtered = df[
         (df['å¯¦ç¸¾ç¨®é¡'] == '27')   # æ­£ç¢ºï¼šç”¨å­—ä¸² '27'
     ]
     ```
  3. **çµ•å°ä¸å¾—**å¯«æˆ `(df['å¯¦ç¸¾ç¨®é¡'] == 27)` æˆ–å…¶ä»–éå­—ä¸²æ–¹å¼ã€‚

# ä¸€èˆ¬æ€§è³‡æ–™æ¢ç´¢èˆ‡åˆ†ææµç¨‹
- é©ç”¨æƒ…å¢ƒï¼šä½¿ç”¨è€…è©¢å•æ’è¡Œï¼ˆæœ€æ…¢ï¼æœ€å¿« N é …ï¼‰ã€æ™‚é–“åˆ‡ç‰‡ï¼ˆå¦‚ 1 æœˆã€Q2ã€æœ€è¿‘ä¸‰å€‹æœˆï¼‰ã€ç†±é–€é …ç›®ã€æ•˜è¿°æ€§çµ±è¨ˆç­‰ã€‚
- å·¥å…·é †åºï¼š
  1. list_files()
  2. read_excel_head(filename, sheet_name, n_rows)
  3. read_excel_file(filename, sheet_name)
  4. analyze_dataframe(query)
- å…±é€šè¦å‰‡ï¼š
  - æ™‚é–“ç¯©é¸å¿…å…ˆæª¢æŸ¥ datetimeï¼Œè‹¥æœªè½‰å‹å‰‡åŸ·è¡Œä¸Šè¿°ã€Œæ¬„ä½å‹æ…‹è™•ç†ã€ä¸­çš„æ—¥æœŸè½‰å‹æ­¥é©Ÿã€‚
  - å¼·åˆ¶ groupbyï¼šä»»ä½•æ¶‰åŠçµ±è¨ˆã€æ’è¡Œã€è¨ˆæ•¸æˆ–é”æ¨™åˆ†æï¼Œæ¨¡å‹å¿…é ˆå…ˆè¾¨è­˜ã€Œå•é¡Œä¸­æåŠçš„æ‰€æœ‰é—œéµç¶­åº¦æ¬„ä½ã€ï¼Œä¸¦å°é€™äº›æ¬„ä½ä¸€èµ·å‘¼å« `groupby(...)` å†åšèšåˆï¼›çµ•ä¸å¯ç›´æ¥åœ¨åŸå§‹ df ä¸Šç”¨ `idxmax()`/`idxmin()` æˆ–åªå°å–®ä¸€æ¬„ä½åš groupbyã€‚
  - ä¿ç•™åŸå§‹å€¼ï¼šæ’è¡Œéœ€æ±‚é ˆä¿ç•™æ‰€æœ‰åŸå§‹æ•¸å€¼ï¼ˆå« -1ã€0ï¼‰ï¼Œä¸¦åŒæ™‚ groupby ä»£ç¢¼èˆ‡åç¨±ï¼Œä¾‹å¦‚ï¼š
    ```python
    # ç¯„ä¾‹ï¼š1 æœˆæ“šé»æ’è¡Œæœ€å¿«
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
    jan = df[df['æ—¥æœŸ'].dt.month == 1]
    summary = jan.groupby(['æ“šé»ä»£ç¢¼','æ“šé»'])['å°æ•¸'].sum().reset_index()
    top_point = summary.loc[summary['å°æ•¸'].idxmax()]
    ```
    è«‹ç›´æ¥å›å‚³ `summary` DataFrame ä¸­çš„å®Œæ•´è¡Œï¼Œè€Œéåªå› tuple(key,value)ã€‚
  - åˆ†å±¤æ’è¡Œï¼š
    1. ç¬¬ä¸€å±¤ç´š groupby + sum â†’ æ‰¾å‡ºç›®æ¨™åˆ†çµ„
    2. ç¯©é¸è©²åˆ†çµ„æ‰€æœ‰è¨˜éŒ„
    3. ç¬¬äºŒå±¤ç´š groupby + sum â†’ æ’åºå–å‰ N



# ç›®æ¨™ vs. å¯¦éš› éŠ·å”®é”æ¨™æ¯”å°æµç¨‹
- é©ç”¨æƒ…å¢ƒï¼šä½¿ç”¨è€…è©¢å•ã€Œç¶“éŠ·å•†ï¼ç‡Ÿæ¥­æ‰€é”æ¨™ç‹€æ³ã€ã€ã€Œç¶“éŠ·å•†ï¼ç‡Ÿæ¥­æ‰€é”æ¨™æ•¸ã€ã€ã€Œç›®æ¨™ vs. å¯¦éš› å·®ç•°åˆ†æã€ç­‰ã€‚
- å·¥å…·é †åºï¼š
  1. list_and_classify_files()
  2. load_excel_file(filename)
  3. classify_file_type(filename)
  4. compare_target_vs_actual(target_key, actual_key)
- å…±é€šè¦å‰‡ï¼š
  - å¤š sheet æª”æ¡ˆç”± load_excel_file ä¸€æ¬¡è®€å…¥æ‰€æœ‰ sheetï¼Œå­˜æ–¼ dataframes["filename::sheet"]ã€‚
  - compare_target_vs_actual åŸ·è¡Œå¾Œé ˆæŠŠåˆä½µçµæœå¯«å› dataframesï¼Œä¸¦ç”±å·¥å…·è¼¸å‡º summary èˆ‡ detailã€‚
  - æ‰€æœ‰æ•¸å­—çµæœå¿…é ˆå¾åˆä½µå¾Œçš„è¡¨æ ¼å…§å®¹è¡ç”Ÿï¼Œç¦æ­¢æ†‘ç©ºæˆ–äºŒæ¬¡è¨ˆç®—ã€‚

# å›ç­”è¦æ±‚
- è«‹å…ˆå›å ±ã€Œå·²é¸æ“‡ï¼šA. ä¸€èˆ¬åˆ†ææµç¨‹ã€æˆ–ã€Œå·²é¸æ“‡ï¼šB. ç›®æ¨™ vs. å¯¦éš›æµç¨‹ã€ã€‚
- ç•¶ä½¿ç”¨è€…è©¢å•ã€ŒæŸç¶“éŠ·å•†é”æ¨™æ•¸é‡ã€æ™‚ï¼š
    1. å…ˆå‘¼å« compare_target_vs_actual(target_key, actual_key) å–å¾— merged_keyã€‚
    2. å†å‘¼å« summarize_performance_summary(merged_key, dealer_name) å–å¾—è©²ç¶“éŠ·å•†çš„ summaryã€‚
    3. æœ€çµ‚å›å‚³çš„ã€Œç¸½ç­†æ•¸ï¼é”æ¨™ç­†æ•¸ï¼é”æ¨™ç‡ã€éƒ½å–è‡ª summarize_performance_summary çš„çµæœï¼Œ
        ä¸å¯å†æ¬¡è‡ªè¡Œè¨ˆç®—ã€‚
- ä¸é ˆé¡¯ç¤ºé—œéµ pandas ç¨‹å¼ç¢¼ç‰‡æ®µèˆ‡é‹è¡Œçµæœã€‚
- æœ€çµ‚å›å‚³æ¸…æ™°çš„ Markdown è¡¨æ ¼ï¼Œä»¥åŠ**å¿…é ˆ**ä½¿ç”¨ compare_target_vs_actual å›å‚³çš„ `summary` æ¬„ä½ä¾†å¡«å……ã€Œç¸½ç­†æ•¸ï¼é”æ¨™ç­†æ•¸ï¼é”æ¨™ç‡ã€ï¼Œä¸å…è¨±æ¨¡å‹å¦è¡Œè¨ˆç®—ã€‚
- è‹¥è³‡æ–™ä¸è¶³æˆ–æ¬„ä½ä¸ç¬¦ï¼Œè«‹æ˜ç¢ºæå‡ºä¸¦è«‹æ±‚è£œå……ã€‚
- è‹¥ä½¿ç”¨è€…è¼¸å…¥çš„æ˜¯ç¶“éŠ·å•†åç¨±èˆ‡ç‡Ÿæ¥­æ‰€åç¨±ï¼Œè«‹åƒç…§ä¸‹åˆ—å°æ‡‰è³‡è¨ŠæŸ¥æ‰¾å°æ‡‰çš„ä»£ç¢¼ï¼š{self.mapping_text}
- **è‹¥çµæœåªå›å‚³äº†æŸå€‹ä»£ç¢¼ï¼ˆå¦‚æ“šé»ä»£ç¢¼ï¼‰ï¼Œå‹™å¿…å†åˆ°åŸå§‹ DataFrame ä¸­ä»¥è©²ä»£ç¢¼ç‚º keyï¼ŒæŠ“å‡ºå°æ‡‰çš„ã€Œæ“šé»åç¨±ã€æˆ–ã€Œç‡Ÿæ¥­æ‰€ã€æ¬„ä½ï¼Œä¸€ä½µå›è¦†**ã€‚
- åœ¨group by ä»£ç¢¼çš„æ™‚å€™ï¼Œå¿…é ˆé€£åŒåç¨±ä¸€ä½µç´å…¥å†å«group byã€‚
"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            ("human", "{input}"),
            ("ai", "{agent_scratchpad}")
        ])
        
        try:
            # è½‰æ›å·¥å…·ç‚º OpenAI Functions æ ¼å¼ï¼ˆèˆ‡åŸç¨‹å¼ç›¸åŒï¼‰
            functions = [format_tool_to_openai_function(tool) for tool in self.tools]
            
            # å‰µå»º agentï¼ˆä½¿ç”¨èˆ‡åŸç¨‹å¼ç›¸åŒçš„é…ç½®ï¼‰
            agent = create_openai_functions_agent(self.llm, self.tools, prompt)
            self.agent_executor = AgentExecutor(
                agent=agent,
                tools=self.tools,
                verbose=True,  # èˆ‡åŸç¨‹å¼ä¿æŒä¸€è‡´
                handle_parsing_errors=True
            )
            
        except Exception as e:
            st.error(f"Agent å‰µå»ºå¤±æ•—: {str(e)}")
    
    def query(self, question: str) -> Dict[str, Any]:
        """æŸ¥è©¢ Agent - ä¿®å¾©ç‰ˆæœ¬é©é…ç¾ä»£ LangChain API"""
        if not self.agent_executor:
            return {
                "output": "âŒ AI åŠ©ç†æœªæ­£ç¢ºåˆå§‹åŒ–ï¼Œè«‹æª¢æŸ¥ OpenAI API Key è¨­å®š",
                "error": True,
                "cost": 0,
                "tokens": 0
            }
        
        try:
            with get_openai_callback() as cb:
                # ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„ LangChain API èª¿ç”¨æ–¹å¼
                response = self.agent_executor.invoke({"input": question})
            
            # è™•ç†å›æ‡‰æ ¼å¼ - æ”¯æ´å¤šç¨®å¯èƒ½çš„å›æ‡‰çµæ§‹
            output_text = ""
            
            if isinstance(response, dict):
                # æ¨™æº–å­—å…¸å›æ‡‰ - å„ªå…ˆæŸ¥æ‰¾ output æ¬„ä½
                if "output" in response:
                    output_text = str(response["output"])
                elif "result" in response:
                    output_text = str(response["result"])  
                elif "answer" in response:
                    output_text = str(response["answer"])
                else:
                    # å¦‚æœæ²’æœ‰æ¨™æº–æ¬„ä½ï¼Œå˜—è©¦æ‰¾åˆ°æœ€ç›¸é—œçš„å…§å®¹
                    possible_keys = ['text', 'content', 'response', 'message']
                    for key in possible_keys:
                        if key in response:
                            output_text = str(response[key])
                            break
                    
                    # å¦‚æœé‚„æ˜¯æ²’æ‰¾åˆ°ï¼Œå°‡æ•´å€‹å›æ‡‰è½‰ç‚ºå­—ç¬¦ä¸²
                    if not output_text:
                        output_text = str(response)
            else:
                # ç›´æ¥å­—ç¬¦ä¸²å›æ‡‰
                output_text = str(response)
            
            # æº–å‚™å›å‚³çµæœ
            result = {
                "output": output_text,
                "cost": cb.total_cost,
                "tokens": cb.total_tokens,
                "successful_requests": cb.successful_requests,
                "error": False,
                "raw_response": response  # ä¿ç•™åŸå§‹å›æ‡‰ç”¨æ–¼ DEBUG
            }
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ä¸­é–“æ­¥é©Ÿè³‡è¨Š
            if isinstance(response, dict) and "intermediate_steps" in response:
                steps = response["intermediate_steps"]
                if steps and len(steps) > 0:
                    steps_info = []
                    for i, step in enumerate(steps):
                        try:
                            # å®‰å…¨åœ°æå–æ­¥é©Ÿè³‡è¨Š
                            tool_name = getattr(step[0], 'tool', 'unknown_tool') if hasattr(step[0], 'tool') else 'step'
                            steps_info.append(f"æ­¥é©Ÿ {i+1}: {tool_name}")
                        except (AttributeError, IndexError):
                            steps_info.append(f"æ­¥é©Ÿ {i+1}: è™•ç†ä¸­")
                    
                    result["steps_summary"] = f"åŸ·è¡Œäº† {len(steps)} å€‹æ­¥é©Ÿ: {', '.join(steps_info)}"
                else:
                    result["steps_summary"] = "å®Œæˆå–®æ­¥è™•ç†"
            
            return result
            
        except Exception as e:
            error_msg = f"âŒ è™•ç†å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            
            # æä¾›æ›´è©³ç´°çš„éŒ¯èª¤è¨ºæ–·
            if "API" in str(e).upper():
                error_msg += "\n\nå¯èƒ½åŸå› ï¼šOpenAI API å•é¡Œï¼Œè«‹æª¢æŸ¥ API Key å’Œç¶²è·¯é€£ç·šã€‚"
            elif "tool" in str(e).lower():
                error_msg += "\n\nå¯èƒ½åŸå› ï¼šåˆ†æå·¥å…·åŸ·è¡ŒéŒ¯èª¤ï¼Œè«‹æª¢æŸ¥è³‡æ–™æ ¼å¼ã€‚"
            elif "parse" in str(e).lower():
                error_msg += "\n\nå¯èƒ½åŸå› ï¼šå›æ‡‰è§£æéŒ¯èª¤ï¼Œè«‹ç°¡åŒ–å•é¡Œé‡æ–°æå•ã€‚"
            
            return {
                "output": error_msg,
                "error": True,
                "cost": 0,
                "tokens": 0,
                "raw_error": str(e)  # ä¿ç•™åŸå§‹éŒ¯èª¤ç”¨æ–¼ DEBUG
            }
    
    # è¼”åŠ©åˆ†ææ–¹æ³•ï¼ˆèˆ‡åŸç¨‹å¼ä¿æŒä¸€è‡´ï¼‰
    def generate_summary(self, df: pd.DataFrame) -> str:
        """ç”Ÿæˆè³‡æ–™æ‘˜è¦"""
        summary = f"""
        ğŸ“Š **è³‡æ–™æ‘˜è¦**
        - ç¸½è¡Œæ•¸: {len(df):,}
        - ç¸½æ¬„æ•¸: {len(df.columns)}
        - ç¼ºå¤±å€¼: {df.isnull().sum().sum():,}
        - é‡è¤‡è¡Œ: {df.duplicated().sum():,}
        - æ•¸å€¼æ¬„ä½: {len(df.select_dtypes(include=['number']).columns)}
        - æ–‡å­—æ¬„ä½: {len(df.select_dtypes(include=['object']).columns)}
        - è¨˜æ†¶é«”ä½¿ç”¨: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB
        """
        return summary
    
    def generate_statistics(self, df: pd.DataFrame) -> str:
        """ç”Ÿæˆçµ±è¨ˆè³‡è¨Š"""
        numeric_df = df.select_dtypes(include=['number'])
        if numeric_df.empty:
            return "æ­¤è³‡æ–™é›†æ²’æœ‰æ•¸å€¼æ¬„ä½å¯é€²è¡Œçµ±è¨ˆåˆ†æ"
        
        stats = numeric_df.describe()
        result = "ğŸ“ˆ **æ•¸å€¼æ¬„ä½çµ±è¨ˆ**\n\n"
        for col in stats.columns:
            result += f"**{col}**\n"
            result += f"  - å¹³å‡å€¼: {stats.loc['mean', col]:.2f}\n"
            result += f"  - æ¨™æº–å·®: {stats.loc['std', col]:.2f}\n"
            result += f"  - æœ€å°å€¼: {stats.loc['min', col]:.2f}\n"
            result += f"  - æœ€å¤§å€¼: {stats.loc['max', col]:.2f}\n\n"
        
        return result
    
    def list_columns(self, df: pd.DataFrame) -> str:
        """åˆ—å‡ºæ¬„ä½è³‡è¨Š"""
        result = "ğŸ“‹ **è³‡æ–™æ¬„ä½è³‡è¨Š**\n\n"
        for i, col in enumerate(df.columns, 1):
            dtype = str(df[col].dtype)
            non_null = df[col].count()
            unique = df[col].nunique()
            result += f"{i}. **{col}** ({dtype})\n"
            result += f"   - éç©ºå€¼: {non_null:,}\n"
            result += f"   - å”¯ä¸€å€¼: {unique:,}\n\n"
        return result
    
    def analyze_missing_values(self, df: pd.DataFrame) -> str:
        """åˆ†æç¼ºå¤±å€¼"""
        missing = df.isnull().sum()
        missing = missing[missing > 0].sort_values(ascending=False)
        
        if missing.empty:
            return "âœ… æ­¤è³‡æ–™é›†æ²’æœ‰ç¼ºå¤±å€¼"
        
        result = "ğŸ” **ç¼ºå¤±å€¼åˆ†æ**\n\n"
        total_rows = len(df)
        
        for col, count in missing.items():
            percentage = (count / total_rows) * 100
            result += f"â€¢ **{col}**: {count:,} å€‹ç¼ºå¤±å€¼ ({percentage:.1f}%)\n"
        
        return result
    
    def general_analysis(self, df: pd.DataFrame, query: str) -> str:
        """ä¸€èˆ¬æ€§åˆ†æ"""
        return f"æ”¶åˆ°æŸ¥è©¢: ã€Œ{query}ã€\n\nç›®å‰è³‡æ–™åŒ…å« {len(df):,} è¡Œ {len(df.columns)} æ¬„çš„è³‡æ–™ã€‚\n\nå¦‚éœ€å…·é«”åˆ†æï¼Œè«‹æä¾›æ›´æ˜ç¢ºçš„å•é¡Œï¼Œä¾‹å¦‚:\nâ€¢ ã€Œé¡¯ç¤ºè³‡æ–™æ‘˜è¦ã€\nâ€¢ ã€Œè¨ˆç®—çµ±è¨ˆè³‡è¨Šã€\nâ€¢ ã€Œåˆ†æç¼ºå¤±å€¼ã€"


# å…¨åŸŸ agent å¯¦ä¾‹
@st.cache_resource
def get_langchain_agent():
    """ç²å–å¿«å–çš„ LangChain Agent"""
    return StreamlitLangChainAgent()


def integrate_existing_tools():
    """
    æ•´åˆç¾æœ‰çš„ solution_combine.py å·¥å…·
    é€™å€‹å‡½æ•¸å¯ä»¥ç”¨ä¾†å°å…¥å’Œæ•´åˆç¾æœ‰çš„åˆ†æå·¥å…·
    """
    try:
        # å˜—è©¦å°å…¥ç¾æœ‰æ¨¡çµ„
        # é€™è£¡å¯ä»¥æ ¹æ“šå¯¦éš›éœ€æ±‚ä¿®æ”¹å°å…¥è·¯å¾‘
        pass
    except ImportError as e:
        st.warning(f"ç„¡æ³•å°å…¥ç¾æœ‰åˆ†æå·¥å…·: {str(e)}")
        return None


# å·¥å…·å‡½æ•¸
def format_response(response: str) -> str:
    """æ ¼å¼åŒ–å›æ‡‰æ–‡å­—"""
    # å¯ä»¥åœ¨é€™è£¡åŠ å…¥æ›´å¤šæ ¼å¼åŒ–é‚è¼¯
    return response


def validate_question(question: str) -> bool:
    """é©—è­‰å•é¡Œæ ¼å¼"""
    if not question or len(question.strip()) < 3:
        return False
    return True