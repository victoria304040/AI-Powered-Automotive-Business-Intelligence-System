"""
HOTAI MOTOR å°ˆç”¨åˆ†æå·¥å…·
åŸºæ–¼ solution1.py, solution3.py, solution_combine.py çš„å®Œæ•´æ•´åˆ
"""
import os
import pandas as pd
import numpy as np
import glob
from typing import List, Dict, Any, Optional
import streamlit as st
from langchain.tools import tool

# å…¨åŸŸå­—å…¸å„²å­˜å¤šå€‹ DataFrameï¼ˆèˆ‡åŸå§‹ç¨‹å¼ä¿æŒä¸€è‡´ï¼‰
dataframes = {}


# ========================================
# Solution1.py å·¥å…· - ä¸€èˆ¬æ€§è³‡æ–™åˆ†æ
# ========================================

@tool
def list_files(file_extension: str = "xlsx") -> List[str]:
    """åˆ—å‡ºç›®å‰ç›®éŒ„ä¸‹æ‰€æœ‰æŒ‡å®šå‰¯æª”åçš„æª”æ¡ˆ"""
    # åœ¨ Streamlit ç’°å¢ƒä¸­ï¼Œæˆ‘å€‘æ”¹ç‚ºåˆ—å‡ºå·²ä¸Šå‚³çš„æª”æ¡ˆ
    if hasattr(st.session_state, 'uploaded_data') and st.session_state.uploaded_data:
        files = [filename for filename in st.session_state.uploaded_data.keys() 
                if filename.endswith(f'.{file_extension}')]
        return files
    return []


@tool
def read_excel_head(filename: str, sheet_name: Optional[str] = None, n_rows: int = 5) -> Dict:
    """é è¦½ Excel æª”æ¡ˆçš„è¡¨é ­å’Œå‰å¹¾ç­†è³‡æ–™"""
    try:
        # å¾ Streamlit session state è®€å–
        if hasattr(st.session_state, 'uploaded_data') and filename in st.session_state.uploaded_data:
            file_info = st.session_state.uploaded_data[filename]
            
            if sheet_name:
                if sheet_name in file_info['data']:
                    df = file_info['data'][sheet_name].head(n_rows)
                else:
                    return {"error": f"æ‰¾ä¸åˆ°å·¥ä½œè¡¨: {sheet_name}"}
            else:
                # å–ç¬¬ä¸€å€‹å·¥ä½œè¡¨
                first_sheet = list(file_info['data'].keys())[0]
                df = file_info['data'][first_sheet].head(n_rows)
                sheet_name = first_sheet
            
            columns = df.columns.tolist()
            sample_data = df.to_dict(orient='records')
            
            return {
                "filename": filename,
                "sheet_name": sheet_name,
                "columns": columns,
                "sample_data": sample_data,
                "total_rows": len(file_info['data'][sheet_name]) if sheet_name in file_info['data'] else 0
            }
        else:
            return {"error": f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}"}
            
    except Exception as e:
        return {"error": f"è®€å–å¤±æ•—: {str(e)}"}


@tool
def read_excel_file(filename: str, sheet_name: Optional[str] = None) -> str:
    """å®Œæ•´è®€å–æŒ‡å®šçš„ Excel æª”æ¡ˆï¼Œä¸¦è¿”å›è³‡æ–™é›†çš„æ‘˜è¦è³‡è¨Š"""
    try:
        if hasattr(st.session_state, 'uploaded_data') and filename in st.session_state.uploaded_data:
            file_info = st.session_state.uploaded_data[filename]
            
            if sheet_name:
                if sheet_name in file_info['data']:
                    df = file_info['data'][sheet_name].copy()
                    
                    # è³‡æ–™æ¸…ç†ï¼ˆä¾æ“š solution1.py é‚è¼¯ï¼‰
                    # 1. æ¸…ç†è³‡æ–™ï¼šå»é™¤å­—ä¸²æ¬„ä½çš„å‰å¾Œç©ºç™½
                    df = df.apply(lambda col: col.str.strip() if col.dtype == "object" else col)
                    
                    # 2. å¼·åˆ¶è½‰æ›ã€Œæ—¥æœŸã€æ¬„ä½ç‚º datetime
                    if "æ—¥æœŸ" in df.columns:
                        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce")
                    
                    # 3. å¼·åˆ¶è½‰æ›ã€Œå¯¦ç¸¾ç¨®é¡ã€æ¬„ä½ç‚ºä¹¾æ·¨å­—ä¸²
                    if "å¯¦ç¸¾ç¨®é¡" in df.columns:
                        df["å¯¦ç¸¾ç¨®é¡"] = df["å¯¦ç¸¾ç¨®é¡"].astype(str).str.strip()
                    
                    # å„²å­˜åˆ°å…¨åŸŸ dataframesï¼ˆä½¿ç”¨ current_df ä½œç‚ºä¸»è¦è³‡æ–™ï¼‰
                    key = f"{filename}::{sheet_name}"
                    dataframes[key] = df
                    dataframes['current_df'] = df  # solution1.py ç›¸å®¹æ€§
                    
                    return f"å·²è¼‰å…¥ {filename}::{sheet_name}ï¼Œè³‡æ–™åˆ—æ•¸: {df.shape[0]}ï¼Œæ¬„ä½æ•¸: {df.shape[1]}ã€‚å¯é€é current_df å­˜å–ã€‚"
                else:
                    return f"âŒ æ‰¾ä¸åˆ°å·¥ä½œè¡¨: {sheet_name}"
            else:
                # è¼‰å…¥æ‰€æœ‰å·¥ä½œè¡¨
                loaded_sheets = []
                for sheet_name, df in file_info['data'].items():
                    # è³‡æ–™æ¸…ç†
                    df = df.apply(lambda col: col.str.strip() if col.dtype == "object" else col)
                    if "æ—¥æœŸ" in df.columns:
                        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce")
                    if "å¯¦ç¸¾ç¨®é¡" in df.columns:
                        df["å¯¦ç¸¾ç¨®é¡"] = df["å¯¦ç¸¾ç¨®é¡"].astype(str).str.strip()
                    
                    key = f"{filename}::{sheet_name}"
                    dataframes[key] = df.copy()
                    loaded_sheets.append(f"{sheet_name}({len(df)}è¡Œ)")
                
                # è¨­å®šç¬¬ä¸€å€‹å·¥ä½œè¡¨ç‚º current_df
                first_sheet_name = list(file_info['data'].keys())[0]
                dataframes['current_df'] = dataframes[f"{filename}::{first_sheet_name}"]
                
                return f"âœ… æˆåŠŸè¼‰å…¥ {filename} çš„æ‰€æœ‰å·¥ä½œè¡¨: {', '.join(loaded_sheets)}"
        else:
            return f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}"
            
    except Exception as e:
        return f"âŒ è¼‰å…¥å¤±æ•—: {str(e)}"


@tool
def analyze_dataframe(query: str) -> str:
    """ä½¿ç”¨ Pandas é‚è¼¯åˆ†æç•¶å‰çš„è³‡æ–™æ¡†æ¶ï¼Œæ ¹æ“šä½¿ç”¨è€…çš„è‡ªç„¶èªè¨€æŸ¥è©¢åŸ·è¡Œæ“ä½œ"""
    if 'current_df' not in dataframes:
        return "å°šæœªè¼‰å…¥ä»»ä½•è³‡æ–™é›†ï¼Œè«‹å…ˆä½¿ç”¨ read_excel_file è¼‰å…¥è³‡æ–™ã€‚"
    
    try:
        df = dataframes['current_df']
        
        # åŸ·è¡Œè³‡æ–™æ¸…ç†ï¼ˆç¢ºä¿è³‡æ–™å‹æ…‹æ­£ç¢ºï¼‰
        # 1. æ—¥æœŸæ¬„ä½è™•ç†
        if "æ—¥æœŸ" in df.columns:
            df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce")
        
        # 2. å¯¦ç¸¾ç¨®é¡æ¬„ä½è™•ç† 
        if "å¯¦ç¸¾ç¨®é¡" in df.columns:
            df["å¯¦ç¸¾ç¨®é¡"] = df["å¯¦ç¸¾ç¨®é¡"].astype(str).str.strip()
        
        # æ›´æ–° dataframes
        dataframes['current_df'] = df
        
        # åŸ·è¡Œå¯¦éš›çš„åˆ†ææŸ¥è©¢ï¼ˆä¾æ“š solution1.py çš„åˆ†æé‚è¼¯ï¼‰
        result_parts = []
        result_parts.append(f"ğŸ“Š **åˆ†æè³‡æ–™**: current_df")
        result_parts.append(f"ğŸ“ˆ **è³‡æ–™è¦æ¨¡**: {len(df):,} è¡Œ Ã— {len(df.columns)} æ¬„")
        
        # æ ¹æ“šæŸ¥è©¢å…§å®¹åŸ·è¡Œå°æ‡‰åˆ†æ
        if any(keyword in query for keyword in ['æ’è¡Œ', 'æœ€å¿«', 'æœ€æ…¢', 'å‰', 'å¾Œ', 'åæ¬¡', 'é€²åº¦']):
            # æ’è¡Œåˆ†æé‚è¼¯ï¼ˆåŸºæ–¼ solution1.pyï¼‰
            result_parts.append("\nğŸ† **æ’è¡Œåˆ†æ**:")
            
            # æ™‚é–“ç¯©é¸è™•ç†
            filtered_df = df
            if any(time_keyword in query for time_keyword in ['1æœˆ', '2æœˆ', '3æœˆ', '4æœˆ', '5æœˆ', '6æœˆ', '1æœˆä»½', '2æœˆä»½']):
                if "æ—¥æœŸ" in df.columns:
                    # æå–æœˆä»½
                    if '1æœˆ' in query:
                        filtered_df = df[df['æ—¥æœŸ'].dt.month == 1]
                    elif '2æœˆ' in query:
                        filtered_df = df[df['æ—¥æœŸ'].dt.month == 2]
                    elif '3æœˆ' in query:
                        filtered_df = df[df['æ—¥æœŸ'].dt.month == 3]
                    elif '4æœˆ' in query:
                        filtered_df = df[df['æ—¥æœŸ'].dt.month == 4]
                    elif '5æœˆ' in query:
                        filtered_df = df[df['æ—¥æœŸ'].dt.month == 5]
                    elif '6æœˆ' in query:
                        filtered_df = df[df['æ—¥æœŸ'].dt.month == 6]
                    
                    result_parts.append(f"æ™‚é–“ç¯©é¸å¾Œè³‡æ–™: {len(filtered_df):,} è¡Œ")
                else:
                    result_parts.append("âš ï¸ æ²’æœ‰æ—¥æœŸæ¬„ä½ï¼Œç„¡æ³•é€²è¡Œæ™‚é–“ç¯©é¸")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å°æ•¸æˆ–æ•¸å€¼æ¬„ä½
            numeric_cols = filtered_df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                # æ‰¾ä¸»è¦æ•¸å€¼æ¬„ä½ï¼ˆå°æ•¸ã€å—è¨‚æ•¸ã€éŠ·å”®æ•¸ç­‰ï¼‰
                main_numeric_col = None
                for col in ['å°æ•¸', 'å—è¨‚æ•¸', 'éŠ·å”®æ•¸', 'ç›®æ¨™æ•¸', 'å¯¦ç¸¾æ•¸']:
                    if col in filtered_df.columns:
                        main_numeric_col = col
                        break
                if not main_numeric_col and len(numeric_cols) > 0:
                    main_numeric_col = numeric_cols[0]
                
                # åŸ·è¡Œ groupby åˆ†æï¼ˆä¾æ“šåŸç¨‹å¼è¦å‰‡ï¼‰
                group_cols = []
                if 'æ“šé»ä»£ç¢¼' in filtered_df.columns and 'æ“šé»' in filtered_df.columns:
                    group_cols = ['æ“šé»ä»£ç¢¼', 'æ“šé»']
                elif 'ç¶“éŠ·å•†ä»£ç¢¼' in filtered_df.columns and 'ç¶“éŠ·å•†åç¨±' in filtered_df.columns:
                    group_cols = ['ç¶“éŠ·å•†ä»£ç¢¼', 'ç¶“éŠ·å•†åç¨±']
                elif 'è»Šç¨®ä»£ç¢¼' in filtered_df.columns and 'è»Šç¨®åç¨±' in filtered_df.columns:
                    group_cols = ['è»Šç¨®ä»£ç¢¼', 'è»Šç¨®åç¨±']
                elif 'æ“šé»ä»£ç¢¼' in filtered_df.columns:
                    group_cols = ['æ“šé»ä»£ç¢¼']
                elif 'ç¶“éŠ·å•†ä»£ç¢¼' in filtered_df.columns:
                    group_cols = ['ç¶“éŠ·å•†ä»£ç¢¼']
                
                if group_cols and main_numeric_col:
                    summary = filtered_df.groupby(group_cols)[main_numeric_col].sum().reset_index()
                    
                    # æ’åºï¼ˆæ ¹æ“šæŸ¥è©¢å…§å®¹æ±ºå®šå‡åºæˆ–é™åºï¼‰
                    ascending = 'æœ€æ…¢' in query or 'æœ€å°‘' in query
                    summary = summary.sort_values(main_numeric_col, ascending=ascending)
                    
                    # é¡¯ç¤ºçµæœ
                    result_type = "æœ€æ…¢" if ascending else "æœ€å¿«"
                    result_parts.append(f"ä¾ {main_numeric_col} æ’è¡Œ ({result_type}å‰5å):")
                    
                    for i, (_, row) in enumerate(summary.head(5).iterrows(), 1):
                        if len(group_cols) > 1:
                            name_display = f"{row[group_cols[0]]} ({row[group_cols[1]]})"
                        else:
                            name_display = str(row[group_cols[0]])
                        result_parts.append(f"  {i}. {name_display}: {row[main_numeric_col]:,}")
                    
                    # å¦‚æœæŸ¥è©¢è¦æ±‚å–®ä¸€çµæœï¼Œè¿”å›ç¬¬ä¸€å
                    if len(summary) > 0:
                        top_result = summary.iloc[0]
                        if len(group_cols) > 1:
                            winner = f"{top_result[group_cols[0]]} ({top_result[group_cols[1]]})"
                        else:
                            winner = str(top_result[group_cols[0]])
                        result_parts.append(f"\nğŸ¯ **çµæœ**: {winner} ({result_type}ï¼Œ{main_numeric_col}: {top_result[main_numeric_col]:,})")
                else:
                    result_parts.append("ç„¡æ³•è­˜åˆ¥é©ç•¶çš„åˆ†çµ„æ¬„ä½é€²è¡Œæ’è¡Œåˆ†æ")
            else:
                result_parts.append("æ²’æœ‰å¯ç”¨çš„æ•¸å€¼æ¬„ä½é€²è¡Œæ’è¡Œåˆ†æ")
        
        elif any(keyword in query for keyword in ['è»Šç¨®', 'è»Šæ¬¾', 'å‹è™Ÿ']):
            # è»Šç¨®åˆ†æ
            if 'è»Šç¨®åç¨±' in df.columns:
                car_analysis = df.groupby('è»Šç¨®åç¨±').agg({
                    col: 'sum' for col in df.select_dtypes(include=['number']).columns
                }).reset_index()
                result_parts.append("\nğŸš— **è»Šç¨®åˆ†æ**:")
                for _, row in car_analysis.head(10).iterrows():
                    main_value = row.iloc[1] if len(row) > 1 else 0  # ç¬¬ä¸€å€‹æ•¸å€¼æ¬„ä½
                    result_parts.append(f"  â€¢ {row['è»Šç¨®åç¨±']}: {main_value:,.0f}")
            else:
                result_parts.append("æ‰¾ä¸åˆ°è»Šç¨®åç¨±æ¬„ä½")
        
        elif any(keyword in query for keyword in ['çµ±è¨ˆ', 'æ‘˜è¦', 'æ¦‚æ³']):
            # çµ±è¨ˆæ‘˜è¦
            numeric_cols = df.select_dtypes(include=['number']).columns
            if len(numeric_cols) > 0:
                result_parts.append("\nğŸ“Š **æ•¸å€¼æ¬„ä½çµ±è¨ˆ**:")
                for col in numeric_cols[:5]:  # é¡¯ç¤ºå‰5å€‹æ•¸å€¼æ¬„ä½
                    stats = df[col].describe()
                    result_parts.append(f"  â€¢ {col}: ç¸½è¨ˆ {stats['sum']:,.0f}, å¹³å‡ {stats['mean']:.1f}, æ¨™æº–å·® {stats['std']:.1f}")
            else:
                result_parts.append("æ²’æœ‰æ•¸å€¼æ¬„ä½å¯é€²è¡Œçµ±è¨ˆ")
        
        else:
            # ä¸€èˆ¬æ€§è³‡è¨Š
            result_parts.append("\nğŸ“‹ **æ¬„ä½è³‡è¨Š**:")
            for i, col in enumerate(df.columns[:8], 1):  # é¡¯ç¤ºå‰8å€‹æ¬„ä½
                non_null = df[col].count()
                unique_count = df[col].nunique()
                result_parts.append(f"  {i}. {col} ({df[col].dtype}): {non_null:,} éç©ºå€¼, {unique_count:,} å”¯ä¸€å€¼")
        
        return "\n".join(result_parts)
        
    except Exception as e:
        return f"âŒ åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"


# ========================================
# Solution3.py å·¥å…· - ç›®æ¨™ vs å¯¦éš›åˆ†æ
# ========================================

@tool
def list_and_classify_files(file_extension: str = "xlsx") -> Dict[str, List[str]]:
    """å›å‚³åˆ†é¡å¾Œçš„æª”æ¡ˆåˆ—è¡¨ï¼štarget / actual / unknown"""
    files = list_files(file_extension)
    grouped = {"target": [], "actual": [], "unknown": []}
    
    for filename in files:
        classification_result = classify_file_type(filename)
        classification = classification_result.get("classification", "unknown")
        grouped[classification].append(filename)
    
    return grouped


@tool
def load_excel_file(filename: str, preview_rows: int = 5) -> Dict:
    """è¼‰å…¥ Excel æ‰€æœ‰å·¥ä½œè¡¨ï¼Œè³‡æ–™å„²å­˜æ–¼å…¨åŸŸè®Šæ•¸ dataframesï¼Œkey ç‚º filename::sheet"""
    try:
        if hasattr(st.session_state, 'uploaded_data') and filename in st.session_state.uploaded_data:
            file_info = st.session_state.uploaded_data[filename]
            preview = {}
            
            for sheet_name, df in file_info['data'].items():
                # è³‡æ–™æ¸…ç†ï¼ˆä¾æ“š solution3.py é‚è¼¯ï¼‰
                # 1. å»é™¤æ‰€æœ‰ object æ¬„ä½çš„å‰å¾Œç©ºç™½
                df = df.apply(lambda col: col.str.strip() if col.dtype == "object" else col)
                
                # 2. å¼·åˆ¶è½‰æ›ã€Œæ—¥æœŸã€æ¬„ä½
                if "æ—¥æœŸ" in df.columns:
                    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], errors="coerce")
                
                # 3. å¼·åˆ¶è½‰æ›ã€Œå¯¦ç¸¾ç¨®é¡ã€æ¬„ä½ç‚ºç´”å­—ä¸²ä¸¦ strip
                if "å¯¦ç¸¾ç¨®é¡" in df.columns:
                    df["å¯¦ç¸¾ç¨®é¡"] = df["å¯¦ç¸¾ç¨®é¡"].astype(str).str.strip()
                
                key = f"{filename}::{sheet_name}"
                dataframes[key] = df
                preview[key] = {
                    "columns": df.columns.tolist(),
                    "sample_data": df.head(preview_rows).to_dict(orient="records"),
                    "rows": len(df),
                    "columns_count": len(df.columns)
                }
            
            return {
                "filename": filename,
                "sheets_loaded": len(file_info['data']),
                "preview": preview
            }
        else:
            return {"error": f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}"}
            
    except Exception as e:
        return {"error": f"è¼‰å…¥å¤±æ•—: {str(e)}"}


@tool
def classify_file_type(filename: str) -> Dict:
    """åˆ†é¡è³‡æ–™è¡¨ç‚º target / actualï¼Œæ ¹æ“šæª”åèˆ‡æ¬„ä½å…§å®¹å›å‚³è©³ç´°èªªæ˜"""
    target_keywords = ["ç›®æ¨™", "target"]
    actual_keywords = ["çµ±è¨ˆ", "å¯¦éš›", "actual", "å¯¦ç¸¾"]
    
    try:
        if hasattr(st.session_state, 'uploaded_data') and filename in st.session_state.uploaded_data:
            file_info = st.session_state.uploaded_data[filename]
            
            for sheet_name, df in file_info['data'].items():
                columns = set(df.columns.str.lower())
                
                if any(kw in filename.lower() or kw in sheet_name.lower() for kw in target_keywords):
                    if columns & {"ç›®æ¨™", "target", "éŠ·å”®ç›®æ¨™", "ç¶“éŠ·å•†"}:
                        return {
                            "filename": filename,
                            "classification": "target",
                            "reason": f"æ–¼ sheetã€{sheet_name}ã€‘ç™¼ç¾ç›®æ¨™ç›¸é—œæ¬„ä½: {columns & {'ç›®æ¨™', 'target', 'éŠ·å”®ç›®æ¨™', 'ç¶“éŠ·å•†'}}"
                        }
                
                if any(kw in filename.lower() or kw in sheet_name.lower() for kw in actual_keywords):
                    if columns & {"å¯¦éš›", "actual", "éŠ·å”®", "éŠ·å”®æ•¸", "å¯¦ç¸¾"}:
                        return {
                            "filename": filename,
                            "classification": "actual",
                            "reason": f"æ–¼ sheetã€{sheet_name}ã€‘ç™¼ç¾å¯¦éš›ç›¸é—œæ¬„ä½: {columns & {'å¯¦éš›', 'actual', 'éŠ·å”®', 'éŠ·å”®æ•¸', 'å¯¦ç¸¾'}}"
                        }
            
            return {
                "filename": filename,
                "classification": "unknown",
                "reason": "ç„¡æ³•æ ¹æ“šæª”æ¡ˆå…§å®¹åˆ¤æ–·é¡å‹"
            }
        else:
            return {"filename": filename, "error": f"æª”æ¡ˆä¸å­˜åœ¨: {filename}"}
            
    except Exception as e:
        return {"filename": filename, "error": str(e)}


@tool
def compare_target_vs_actual(target_key: str, actual_key: str) -> Dict[str, Any]:
    """
    æ¯”å°ç›®æ¨™èˆ‡å¯¦éš›è³‡æ–™ï¼Œåªç”¨ç¶“éŠ·å•†ä»£ç¢¼ + æ“šé»ä»£ç¢¼åš joinï¼Œ
    è‹¥å¯¦ç¸¾è¡¨ä¸­æœ‰åç¨±æ¬„ä½ï¼ˆå¦‚ ç¶“éŠ·å•†åç¨±ã€æ“šé»ï¼‰ï¼Œå‰‡åœ¨åˆä½µå¾Œä¸€ä½µå¸¶å‡ºã€‚
    key ç‚º filename::sheet_name æ ¼å¼ã€‚
    """
    try:
        # 1. æª¢æŸ¥æ˜¯å¦å·²è¼‰å…¥
        if target_key not in dataframes or actual_key not in dataframes:
            return {"error": f"è«‹ç¢ºèªé€™å…©å€‹ key æ˜¯å¦å­˜åœ¨æ–¼ dataframesï¼š{target_key}, {actual_key}"}
        
        df_target = dataframes[target_key].copy()
        df_actual = dataframes[actual_key].copy()
        
        # 2. æ ¸å¿ƒæ¬„ä½ï¼ˆä¾æ“š solution3.py é‚è¼¯ï¼‰
        dist_code_col = "ç¶“éŠ·å•†ä»£ç¢¼"
        target_point_col = "æ“šé»ä»£ç¢¼"
        actual_point_col = "ç‡Ÿæ¥­æ‰€ä»£ç¢¼"
        
        # 3. ç¢ºèªå¿…è¦æ¬„ä½
        for col in (dist_code_col, target_point_col):
            if col not in df_target.columns:
                return {"error": f"ç›®æ¨™è¡¨ç¼ºå°‘å¿…è¦æ¬„ä½: {col}"}
        for col in (dist_code_col, actual_point_col):
            if col not in df_actual.columns:
                return {"error": f"å¯¦éš›è¡¨ç¼ºå°‘å¿…è¦æ¬„ä½: {col}"}
        
        # 4. æ‰¾éŠ·å”®æ¬„ä½
        target_sales_col = next((c for c in df_target.columns if any(k in c for k in ["ç›®æ¨™", "ç›®æ¨™æ•¸", "ç›®æ¨™éŠ·å”®æ•¸"])), None)
        actual_sales_col = next((c for c in df_actual.columns if any(k in c for k in ["å¯¦ç¸¾", "éŠ·å”®", "å—è¨‚"])), None)
        if not target_sales_col or not actual_sales_col:
            return {"error": "ç¼ºå°‘ç›®æ¨™æˆ–å¯¦éš›éŠ·å”®æ¬„ä½"}
        
        df_target[target_sales_col] = pd.to_numeric(df_target[target_sales_col], errors="coerce")
        df_actual[actual_sales_col] = pd.to_numeric(df_actual[actual_sales_col], errors="coerce")
        
        # 5. group by åªç”¨ä»£ç¢¼å»èšåˆï¼ˆä¾æ“š solution3.py é‚è¼¯ï¼‰
        df_t = (
            df_target
            .groupby([dist_code_col, target_point_col], as_index=False)[target_sales_col]
            .sum()
            .rename(columns={target_point_col: actual_point_col, target_sales_col: "target_sales"})
        )
        
        # å¦‚æœå¯¦ç¸¾è¡¨æœ‰ç¶“éŠ·å•†åç¨±ã€æ“šé»åç¨±ï¼Œå°±åœ¨èšåˆæ™‚ä¸€èµ·ä¿ç•™
        extra_cols = []
        if "ç¶“éŠ·å•†åç¨±" in df_actual.columns:
            extra_cols.append("ç¶“éŠ·å•†åç¨±")
        if "æ“šé»" in df_actual.columns:
            extra_cols.append("æ“šé»")
        
        df_a = (
            df_actual
            .groupby([dist_code_col, actual_point_col] + extra_cols, as_index=False)[actual_sales_col]
            .sum()
            .rename(columns={actual_sales_col: "actual_sales"})
        )
        
        # 6. åˆä½µ
        df_merge = pd.merge(
            df_t, df_a,
            on=[dist_code_col, actual_point_col],
            how="inner"
        )
        df_merge["é”æ¨™"] = df_merge["actual_sales"] >= df_merge["target_sales"]
        
        # 7. å¯«å›å…¨åŸŸ
        merged_key = f"merged_{target_key.split('::')[0]}_{actual_key.split('::')[0]}"
        dataframes[merged_key] = df_merge
        
        # 8. summary
        total = int(len(df_merge))
        achieved = int(df_merge["é”æ¨™"].sum())
        rate = achieved / total if total else 0.0
        
        return {
            "merged_key": merged_key,
            "target_file": target_key,
            "actual_file": actual_key,
            "merge_columns": [dist_code_col, actual_point_col],
            "target_sales_column": target_sales_col,
            "actual_sales_column": actual_sales_col,
            "total_records": total,
            "achieved_records": achieved,
            "achievement_rate": round(rate * 100, 1),
            "summary": f"ç¸½ç­†æ•¸: {total}, é”æˆç­†æ•¸: {achieved}, é”æˆç‡: {rate*100:.1f}%",
            "detail": df_merge.to_dict(orient="records")
        }
        
    except Exception as e:
        return {"error": f"æ¯”è¼ƒéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}


@tool
def summarize_performance_summary(merged_key: str, dealer_name: Optional[str] = None) -> Dict:
    """ç¸½çµç¸¾æ•ˆæ‘˜è¦ï¼ˆé‡å°ç‰¹å®šç¶“éŠ·å•†ï¼‰"""
    try:
        if merged_key not in dataframes:
            return {"error": f"åˆä½µè³‡æ–™ {merged_key} ä¸å­˜åœ¨ï¼Œè«‹å…ˆåŸ·è¡Œ compare_target_vs_actual"}
        
        df = dataframes[merged_key]
        
        if dealer_name:
            # ç¯©é¸ç‰¹å®šç¶“éŠ·å•†
            dealer_conditions = [
                df['ç¶“éŠ·å•†åç¨±'].str.contains(dealer_name, case=False, na=False) if 'ç¶“éŠ·å•†åç¨±' in df.columns else pd.Series([False] * len(df)),
                df['æ“šé»'].str.contains(dealer_name, case=False, na=False) if 'æ“šé»' in df.columns else pd.Series([False] * len(df)),
                df['ç‡Ÿæ¥­æ‰€'].str.contains(dealer_name, case=False, na=False) if 'ç‡Ÿæ¥­æ‰€' in df.columns else pd.Series([False] * len(df))
            ]
            
            dealer_mask = pd.concat(dealer_conditions, axis=1).any(axis=1)
            filtered_df = df[dealer_mask]
            
            if len(filtered_df) == 0:
                return {"error": f"æ‰¾ä¸åˆ°ç¶“éŠ·å•† '{dealer_name}' çš„è³‡æ–™"}
            
            df = filtered_df
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        total_records = len(df)
        achieved_records = len(df[df['é”æ¨™'] == True])
        achievement_rate = (achieved_records / total_records * 100) if total_records > 0 else 0
        
        # è¨ˆç®—æ•¸å€¼ç¸½è¨ˆ
        target_sales_sum = df['target_sales'].sum() if 'target_sales' in df.columns else 0
        actual_sales_sum = df['actual_sales'].sum() if 'actual_sales' in df.columns else 0
        overall_achievement = (actual_sales_sum / target_sales_sum * 100) if target_sales_sum > 0 else 0
        
        summary = {
            "dealer_name": dealer_name or "å…¨éƒ¨ç¶“éŠ·å•†",
            "total_records": total_records,
            "achieved_records": achieved_records,
            "achievement_rate": round(achievement_rate, 1),
            "total_target": target_sales_sum,
            "total_actual": actual_sales_sum,
            "overall_achievement": round(overall_achievement, 1),
            "summary_text": f"ç¸½ç­†æ•¸: {total_records}, é”æˆç­†æ•¸: {achieved_records}, é”æˆç‡: {achievement_rate:.1f}%"
        }
        
        return summary
        
    except Exception as e:
        return {"error": f"ç¸½çµçµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}


# ========================================
# æ˜ å°„è¡¨è™•ç†ï¼ˆä¾†è‡ª solution3.pyï¼‰
# ========================================

def generate_mapping_text(mapping_file: str) -> str:
    """ç”Ÿæˆæ˜ å°„è¡¨æ–‡å­—"""
    try:
        # åœ¨ Streamlit ç’°å¢ƒä¸­å¾ session state è®€å–
        if hasattr(st.session_state, 'uploaded_data') and mapping_file in st.session_state.uploaded_data:
            file_info = st.session_state.uploaded_data[mapping_file]
            first_sheet = list(file_info['data'].keys())[0]
            df = file_info['data'][first_sheet]
            
            mapping_lines = []
            for _, row in df.iterrows():
                # ä¾æ“š solution3.py çš„é‚è¼¯è™•ç†
                if len(row) >= 4:  # å‡è¨­æœ‰ç¶“éŠ·å•†åç¨±ã€ç¶“éŠ·å•†ä»£ç¢¼ã€ç‡Ÿæ¥­æ‰€åç¨±ã€ç‡Ÿæ¥­æ‰€ä»£ç¢¼
                    dealer_name = str(row.iloc[0]).strip()
                    dealer_code = str(row.iloc[1]).strip()  
                    site_name = str(row.iloc[2]).strip()
                    site_code = str(row.iloc[3]).strip()
                    
                    line = f"({dealer_name}, {site_name}) â†’ ({dealer_code}, {site_code})"
                    mapping_lines.append(line)
            
            mapping_str = "\n".join(mapping_lines)
            return f"æ˜ å°„è³‡æ–™å¦‚ä¸‹ï¼š\n{mapping_str}"
        else:
            return "æ˜ å°„è¡¨æª”æ¡ˆæœªæ‰¾åˆ°æˆ–æœªä¸Šå‚³"
    except Exception as e:
        return f"æ˜ å°„è¡¨è¼‰å…¥å¤±æ•—: {str(e)}"


# ========================================
# æ¥­å‹™è¨ˆç®—å™¨é¡
# ========================================

class BusinessCalculator:
    """æ¥­å‹™æŒ‡æ¨™è¨ˆç®—å™¨"""
    
    @staticmethod
    def calculate_achievement_rate(actual: float, target: float) -> float:
        """è¨ˆç®—é”æˆç‡ = å¯¦ç¸¾ / ç›®æ¨™ Ã— 100%"""
        if target == 0:
            return 0.0
        return round((actual / target) * 100, 1)
    
    @staticmethod
    def calculate_yoy_growth(current_year: float, last_year: float) -> float:
        """è¨ˆç®—å»å¹´æ¯” = ä»Šå¹´ / å»å¹´ Ã— 100%"""
        if last_year == 0:
            return 0.0
        return round((current_year / last_year) * 100, 1)
    
    @staticmethod
    def calculate_mom_growth(current_month: float, last_month: float) -> float:
        """è¨ˆç®—å‰æœˆæ¯” = æœ¬æœˆ / ä¸Šæœˆ Ã— 100%"""
        if last_month == 0:
            return 0.0
        return round((current_month / last_month) * 100, 1)
    
    @staticmethod
    def calculate_progress_rate(current: float, target: float) -> float:
        """è¨ˆç®—æ¨é€²ç‡ = ç›®å‰é€²åº¦ / ç›®æ¨™ Ã— 100%"""
        if target == 0:
            return 0.0
        return round((current / target) * 100, 1)


# ========================================
# å–å¾—æ‰€æœ‰å·¥å…·çš„å‡½æ•¸ï¼ˆä¾› LangChain ä½¿ç”¨ï¼‰
# ========================================

def get_all_tools():
    """è¿”å›æ‰€æœ‰å¯ç”¨çš„åˆ†æå·¥å…·ï¼ˆæ•´åˆ solution1.py å’Œ solution3.pyï¼‰"""
    return [
        # Solution1.py å·¥å…·
        list_files,
        read_excel_head,
        read_excel_file,
        analyze_dataframe,
        # Solution3.py å·¥å…·  
        list_and_classify_files,
        load_excel_file,
        classify_file_type,
        compare_target_vs_actual,
        summarize_performance_summary
    ]